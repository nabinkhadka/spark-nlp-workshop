{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "BioNLP-NER.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h93jK9WJ6MC",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/enterprise/healthcare/BioNLP_NER.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HBLgIZnPuze",
        "colab_type": "text"
      },
      "source": [
        "## BioNLP Named Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4i7ZpBduPxlg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cfe4a323-a748-4f30-f556-54908bebf49a"
      },
      "source": [
        "import json\n",
        "\n",
        "with open('keys.json') as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "license_keys.keys()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['version', 'jsl_version', 'secret', 'SPARK_NLP_LICENSE', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY', 'JSL_OCR_LICENSE', 'JSL_OCR_SECRET'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtNEVtvuPxc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "af245ff5-873e-41f3-f472-374553942ee0"
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "secret = license_keys['secret']\n",
        "os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n",
        "os.environ['JSL_OCR_LICENSE'] = license_keys['JSL_OCR_LICENSE']\n",
        "os.environ['AWS_ACCESS_KEY_ID']= license_keys['AWS_ACCESS_KEY_ID']\n",
        "os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n",
        "version = license_keys['version']\n",
        "jsl_version = license_keys['jsl_version']\n",
        "\n",
        "! python -m pip install --upgrade spark-nlp-jsl==$jsl_version  --extra-index-url https://pypi.johnsnowlabs.com/$secret\n",
        "\n",
        "import sparknlp\n",
        "\n",
        "print (sparknlp.version())\n",
        "\n",
        "import json\n",
        "import os\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp_jsl\n",
        "\n",
        "\n",
        "\n",
        "def start(secret):\n",
        "    builder = SparkSession.builder \\\n",
        "        .appName(\"Spark NLP Licensed\") \\\n",
        "        .master(\"local[*]\") \\\n",
        "        .config(\"spark.driver.memory\", \"16G\") \\\n",
        "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
        "        .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
        "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:\"+version) \\\n",
        "        .config(\"spark.jars\", \"https://pypi.johnsnowlabs.com/\"+secret+\"/spark-nlp-jsl-\"+jsl_version+\".jar\")\n",
        "      \n",
        "    return builder.getOrCreate()\n",
        "\n",
        "\n",
        "spark = start(secret) # if you want to start the session with custom params as in start function above\n",
        "# sparknlp_jsl.start(secret)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_252\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
            "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.johnsnowlabs.com/scwgF2mD1U\n",
            "Collecting spark-nlp-jsl==2.5.4rc2\n",
            "  Downloading https://pypi.johnsnowlabs.com/scwgF2mD1U/spark-nlp-jsl/spark-nlp-jsl-2.5.4rc2.tar.gz\n",
            "Collecting pyspark==2.4.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 52kB/s \n",
            "\u001b[?25hCollecting spark-nlp==2.5.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/99/7a306dd04623ae25d2bd53a190c0b695fc72043773d5ae0870b7aa53d8e2/spark_nlp-2.5.4-py2.py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 36.9MB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 31.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: spark-nlp-jsl, pyspark\n",
            "  Building wheel for spark-nlp-jsl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spark-nlp-jsl: filename=spark_nlp_jsl-2.5.4rc2-cp36-none-any.whl size=22983 sha256=8d3a831e5323b4c891a6832469c3ced5e3774eecba4fe997fbc1fdaa228c66b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/aa/21/fd766748d93cdb7e75f311749ee5e90cc531837704e182302e\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130388 sha256=e8f9ac73a111430b065a343571cf6677c30a73e398a4f03bd84d5ac6d25051ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built spark-nlp-jsl pyspark\n",
            "Installing collected packages: py4j, pyspark, spark-nlp, spark-nlp-jsl\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4 spark-nlp-2.5.4 spark-nlp-jsl-2.5.4rc2\n",
            "2.5.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_acEvbXPuzi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "64ea9892-e8c7-4874-84ae-9f1a1f865369"
      },
      "source": [
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentence = SentenceDetector()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentence')\n",
        "\n",
        "token = Tokenizer()\\\n",
        "    .setInputCols(['sentence'])\\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
        "  .setInputCols([\"sentence\", \"token\"])\\\n",
        "  .setOutputCol(\"embeddings\")\n",
        "\n",
        "clinical_pos = PerceptronModel.pretrained(\"pos_clinical\", \"en\", \"clinical/models\") \\\n",
        "  .setInputCols([\"sentence\", \"token\"]) \\\n",
        "  .setOutputCol(\"pos\")\n",
        "\n",
        "dependency_parser = DependencyParserModel.pretrained(\"dependency_conllu\") \\\n",
        "  .setInputCols([\"sentence\",\"token\", \"pos\"]) \\\n",
        "  .setOutputCol(\"dependency\")\n",
        "\n",
        "bio_ner = NerDLModel.pretrained('ner_bionlp', 'en', 'clinical/models')\n",
        "\n",
        "converter = NerConverter()\\\n",
        "  .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
        "  .setOutputCol(\"ner_span\")\n",
        "\n",
        "clinical_ner_pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        sentence,\n",
        "        token,\n",
        "        embeddings,\n",
        "        clinical_pos,\n",
        "        dependency_parser,\n",
        "        bio_ner,\n",
        "        converter])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embeddings_clinical download started this may take some time.\n",
            "Approximate size to download 1.6 GB\n",
            "[OK!]\n",
            "pos_clinical download started this may take some time.\n",
            "Approximate size to download 1.7 MB\n",
            "[OK!]\n",
            "dependency_conllu download started this may take some time.\n",
            "Approximate size to download 16.6 MB\n",
            "[OK!]\n",
            "ner_bionlp download started this may take some time.\n",
            "Approximate size to download 13.9 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Apm2EOd3Puzl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "8017dbf8-cad8-4f00-8525-a95dcdbb56f7"
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "text=\"\"\"\n",
        "Stage 4 adenocarcinoma of lung with b/l lung nodules , probable L-2 metastasis and a negative brain MRI . Molecular testing of tumor demonstrates EGFR mutation . On Tarceva . Disease Stable . Plan Chemotherapy toxicity reviewed again . Patient agrees to proceed . Counseling time : 40 mins . 1 ) Continue Tarceva for lung cancer . CT CAP ordered before next visit 2 ) Continue anti-anxiety medication 3 ) Xgeva today 4 ) Return in 1 month with labs , after scan\n",
        "\"\"\"\n",
        "\n",
        "prediction_data = spark.createDataFrame([[text]]).toDF(\"text\")\n",
        "\n",
        "prediction_data.show(truncate=False)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|\n",
            "Stage 4 adenocarcinoma of lung with b/l lung nodules , probable L-2 metastasis and a negative brain MRI . Molecular testing of tumor demonstrates EGFR mutation . On Tarceva . Disease Stable . Plan Chemotherapy toxicity reviewed again . Patient agrees to proceed . Counseling time : 40 mins . 1 ) Continue Tarceva for lung cancer . CT CAP ordered before next visit 2 ) Continue anti-anxiety medication 3 ) Xgeva today 4 ) Return in 1 month with labs , after scan\n",
            "|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGJUJbYgPuzo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "1293b715-572f-4844-dd25-161a4d617363"
      },
      "source": [
        "\n",
        "prediction_model=clinical_ner_pipeline.fit(prediction_data)\n",
        "\n",
        "preds = prediction_model.transform(prediction_data)\n",
        "\n",
        "preds.select(F.explode(F.arrays_zip(\"ner_span.result\",\"ner_span.metadata\")).alias(\"entities\")) \\\n",
        ".select(F.expr(\"entities['0']\").alias(\"chunk\"),\n",
        "        F.expr(\"entities['1'].entity\").alias(\"entity\"))\\\n",
        "        .show(truncate=False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+----------------------+\n",
            "|chunk         |entity                |\n",
            "+--------------+----------------------+\n",
            "|adenocarcinoma|Cancer                |\n",
            "|lung          |Organ                 |\n",
            "|lung nodules  |Pathological_formation|\n",
            "|L-2           |Cell                  |\n",
            "|brain         |Organ                 |\n",
            "|tumor         |Cancer                |\n",
            "|EGFR          |Gene_or_gene_product  |\n",
            "|Tarceva       |Simple_chemical       |\n",
            "|Patient       |Organism              |\n",
            "|lung cancer   |Cancer                |\n",
            "+--------------+----------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6_Lri44Puzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}