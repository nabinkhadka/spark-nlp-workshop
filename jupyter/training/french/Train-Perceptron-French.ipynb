{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Train-Perceptron-French.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NcrfGVpLv2Xx"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/french/Train-Perceptron-French.ipynb)\n","\n","## 0. Colab Setup"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1589640976843,"user_tz":-120,"elapsed":69235,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}},"id":"AcKqfUfOwBoS","outputId":"cc3485b6-8288-4216-8865-ad2754406f73","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["import os\n","\n","# Install java\n","! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n","! java -version\n","\n","# Install pyspark\n","! pip install --ignore-installed -q pyspark==2.4.4\n","\n","# Install Spark NLP\n","! pip install --ignore-installed -q spark-nlp==2.5"],"execution_count":1,"outputs":[{"output_type":"stream","text":["openjdk version \"1.8.0_252\"\n","OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n","OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n","\u001b[K     |████████████████████████████████| 215.7MB 61kB/s \n","\u001b[K     |████████████████████████████████| 204kB 44.1MB/s \n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 122kB 2.7MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0koUdx-qv2X3"},"source":["# Train POS Tagger in French by Spark NLP\n","### Based on Universal Dependency `UD_French-GSD` version 2.3\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EqaPFY67v2X5","colab":{}},"source":["import sys\n","import time\n","\n","#Spark ML and SQL\n","from pyspark.ml import Pipeline, PipelineModel\n","from pyspark.sql.functions import array_contains\n","from pyspark.sql import SparkSession\n","from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n","#Spark NLP\n","import sparknlp\n","from sparknlp.annotator import *\n","from sparknlp.common import RegexRule\n","from sparknlp.base import DocumentAssembler, Finisher\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IxoKOXacv2YG"},"source":["### Let's create a Spark Session for our app"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1589641042606,"user_tz":-120,"elapsed":134964,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}},"id":"h3JFtb73v2YI","outputId":"11b27317-0a3b-4f01-d8de-ae3f629323b2","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["spark = sparknlp.start()\n","\n","print(\"Spark NLP version: \", sparknlp.version())\n","print(\"Apache Spark version: \", spark.version)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Spark NLP version:  2.5.0\n","Apache Spark version:  2.4.4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jOW45P_Wv2YQ"},"source":["Let's prepare our training datasets containing `token_posTag` like `de_DET`. You can download this data set from Amazon S3:\n","\n","```\n","wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/fr/pos/UD_French/UD_French-GSD_2.3.txt -P /tmp\n","```"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1589641046004,"user_tz":-120,"elapsed":138352,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}},"id":"8E6rlnU3v2YR","outputId":"49b7045e-a871-429a-868d-9d4f9997aa8e","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/fr/pos/UD_French/UD_French-GSD_2.3.txt -P /tmp"],"execution_count":4,"outputs":[{"output_type":"stream","text":["--2020-05-16 14:57:22--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/fr/pos/UD_French/UD_French-GSD_2.3.txt\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.168.181\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.168.181|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3565213 (3.4M) [text/plain]\n","Saving to: ‘/tmp/UD_French-GSD_2.3.txt’\n","\n","UD_French-GSD_2.3.t 100%[===================>]   3.40M  2.49MB/s    in 1.4s    \n","\n","2020-05-16 14:57:25 (2.49 MB/s) - ‘/tmp/UD_French-GSD_2.3.txt’ saved [3565213/3565213]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PgrS-fz7v2YY","colab":{}},"source":["from sparknlp.training import POS\n","training_data = POS().readDataset(\n","    spark=spark,\n","    path=\"/tmp/UD_French-GSD_2.3.txt\",\n","    delimiter=\"_\",\n","    outputPosCol=\"tags\",\n","    outputDocumentCol=\"document\",\n","    outputTextCol=\"text\"\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1589641055414,"user_tz":-120,"elapsed":147751,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}},"id":"3p1xcWIjv2Yf","outputId":"900066d2-12be-43fe-c8a7-84b09607d9a8","colab":{"base_uri":"https://localhost:8080/","height":459}},"source":["training_data.show()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["+--------------------+--------------------+--------------------+\n","|                text|            document|                tags|\n","+--------------------+--------------------+--------------------+\n","|Les commotions cé...|[[document, 0, 11...|[[pos, 0, 2, DET,...|\n","|L' œuvre est situ...|[[document, 0, 82...|[[pos, 0, 1, DET,...|\n","|Le comportement d...|[[document, 0, 18...|[[pos, 0, 1, DET,...|\n","|Toutefois , les f...|[[document, 0, 44...|[[pos, 0, 8, ADV,...|\n","|Ismene entre et a...|[[document, 0, 80...|[[pos, 0, 5, PROP...|\n","|je reviendrais av...|[[document, 0, 28...|[[pos, 0, 1, PRON...|\n","|Les forfaits comp...|[[document, 0, 30...|[[pos, 0, 2, DET,...|\n","|Il prévient que d...|[[document, 0, 99...|[[pos, 0, 1, PRON...|\n","|Ils tiraient à ba...|[[document, 0, 43...|[[pos, 0, 2, PRON...|\n","|Le château est en...|[[document, 0, 44...|[[pos, 0, 1, DET,...|\n","|En effet , la bir...|[[document, 0, 10...|[[pos, 0, 1, ADP,...|\n","|Le point final de...|[[document, 0, 15...|[[pos, 0, 1, DET,...|\n","|L' information gé...|[[document, 0, 53...|[[pos, 0, 1, DET,...|\n","|Motivé par la cha...|[[document, 0, 21...|[[pos, 0, 5, VERB...|\n","|Il exploitait un ...|[[document, 0, 12...|[[pos, 0, 1, PRON...|\n","|Plus tard dans la...|[[document, 0, 84...|[[pos, 0, 3, ADV,...|\n","|Ils deviennent al...|[[document, 0, 97...|[[pos, 0, 2, PRON...|\n","|Le chevalier lui ...|[[document, 0, 17...|[[pos, 0, 1, DET,...|\n","|Créée au cours du...|[[document, 0, 15...|[[pos, 0, 4, VERB...|\n","|On ne peut éviter...|[[document, 0, 11...|[[pos, 0, 1, PRON...|\n","+--------------------+--------------------+--------------------+\n","only showing top 20 rows\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CBzSVba-v2Yr","colab":{}},"source":["document_assembler = DocumentAssembler() \\\n","    .setInputCol(\"text\")\n","\n","sentence_detector = SentenceDetector() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"sentence\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"sentence\"]) \\\n","    .setOutputCol(\"token\")\\\n","    .setPrefixPattern(\"\\\\A([^\\\\s\\\\p{L}\\\\d\\\\$\\\\.#]*)\")\\\n","    .setSuffixPattern(\"([^\\\\s\\\\p{L}\\\\d]?)([^\\\\s\\\\p{L}\\\\d]*)\\\\z\")\\\n","    .setInfixPatterns([\n","        \"([\\\\p{L}\\\\w]+'{1})\",\n","        \"([\\\\$#]?\\\\d+(?:[^\\\\s\\\\d]{1}\\\\d+)*)\",\n","        \"((?:\\\\p{L}\\\\.)+)\",\n","        \"((?:\\\\p{L}+[^\\\\s\\\\p{L}]{1})+\\\\p{L}+)\",\n","        \"([\\\\p{L}\\\\w]+)\"\n","    ])\n","\n","posTagger = PerceptronApproach() \\\n","    .setNIterations(6) \\\n","    .setInputCols([\"sentence\", \"token\"]) \\\n","    .setOutputCol(\"pos\") \\\n","    .setPosCol(\"tags\")\n","    \n","pipeline = Pipeline(stages=[\n","    document_assembler, \n","    sentence_detector, \n","    tokenizer,\n","    posTagger\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1589641216400,"user_tz":-120,"elapsed":308726,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}},"id":"ozE0ZwKuv2Y2","outputId":"f5c08ff6-8d32-4ce2-fd21-76321bf0664a","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["%%time\n","\n","# Let's train our Pipeline by using our training dataset\n","model = pipeline.fit(training_data)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["CPU times: user 68.2 ms, sys: 17.6 ms, total: 85.8 ms\n","Wall time: 2min 40s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PVkYWiTZv2Y_"},"source":["This is our testing DataFrame where we get some sentences in French. We are going to use our trained Pipeline to transform these sentence and predict each token's `Part Of Speech`."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2vQq_Ps_v2ZA","colab":{}},"source":["dfTest = spark.createDataFrame([\n","    \"Je sens qu'entre ça et les films de médecins et scientifiques fous que nous avons déjà vus, nous pourrions emprunter un autre chemin pour l'origine.\",\n","    \"On pourra toujours parler à propos d'Averroès de décentrement du Sujet.\"\n","], StringType()).toDF(\"text\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gNF94YHDv2ZG","colab":{}},"source":["predict = model.transform(dfTest)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1589641217862,"user_tz":-120,"elapsed":310172,"user":{"displayName":"Christian Kasim Loan","photoUrl":"","userId":"14469489166467359317"}},"id":"o-CU0ituv2ZM","outputId":"8cb25702-ffdc-4b84-80cb-850c34fc4391","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["predict.select(\"token.result\", \"pos.result\").show()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["+--------------------+--------------------+\n","|              result|              result|\n","+--------------------+--------------------+\n","|[Je, sens, qu'ent...|[PRON, NOUN, VERB...|\n","|[On, pourra, touj...|[PRON, VERB, ADV,...|\n","+--------------------+--------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8mkCYL7tv2ZT","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}