{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_Training_Template.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4E3CowahVDwv",
        "bqs7tK3CVLCm",
        "eSnBCPFyVtPE",
        "Bj3jxAaNWifE"
      ],
      "authorship_tag": "ABX9TyML2iYIe+iT9hS7w5o77yJp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nabinkhadka/spark-nlp-workshop/blob/master/NER_Training_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbmcfOFhUuFp"
      },
      "source": [
        "# Customize training pipeline in Annotation Lab\n",
        "This is just a template to help understand how you can define the custom pipelines for Annotation Lab.\n",
        "\n",
        "Annotation Lab only supports the change in training pipeline.\n",
        "\n",
        "## IMPORTANT:\n",
        "Do not update any cells under header with **(X)**\n",
        "\n",
        "So make a copy of this notebook, update only the training pipeline section, download it to your computer and upload it to Annotation Lab from Project Setup Page.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E3CowahVDwv"
      },
      "source": [
        "# Setup Environment (X)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bfKx7tIVINy"
      },
      "source": [
        "import sparknlp_jsl\n",
        "# Setup environment for running spark nlp.\n",
        "# https://nlp.johnsnowlabs.com/docs/en/quickstart\n",
        "# https://github.com/JohnSnowLabs/spark-nlp-workshop\n",
        "spark = sparknlp_jsl.start(\"{secret.code}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqs7tK3CVLCm"
      },
      "source": [
        "# Prepare dataset (X)\n",
        "- Save completions to disk\n",
        "- Convert the Annotation Lab completions to Conll DataFrame format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyUpFsb_VPZV"
      },
      "source": [
        "# Based on type of project (NER/Classification/Assertion),\n",
        "# we export completions (annotated data) as JSON file\n",
        "def save_data_alab_completions():\n",
        "    # Annotation Lab already has implemented this\n",
        "    pass\n",
        "\n",
        "saved_path = save_data_alab_completions()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P84Tch79VVwP"
      },
      "source": [
        "# Now we create conll dataframe and take it as trainable dataset\n",
        "def create_conll_df(path):\n",
        "    # Fill here\n",
        "    pass\n",
        "\n",
        "train_dataset = create_conll_df(saved_path)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSnBCPFyVtPE"
      },
      "source": [
        "# Define Training Pipeline (Update Me)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO9nxhSqVvyY"
      },
      "source": [
        "# Imports needed for setting up the custom pipeline\n",
        "from sparknlp.base import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "from sparknlp.annotator import WordEmbeddingsModel"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3ufK-QAWRTL"
      },
      "source": [
        "embeddings = (\n",
        "    WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\n",
        "    .setInputCols([\"sentence\", \"token\"])\n",
        "    .setOutputCol(\"embeddings\")\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Sl6h1BNWZg-"
      },
      "source": [
        "ner_tagger = (\n",
        "    NerDLApproach()\n",
        "    .setInputCols([\"sentence\", \"token\", \"embeddings\"])\n",
        "    .setOutputCol(\"ner\")\n",
        "    .setLabelColumn(\"label\")\n",
        "    .setBatchSize(64)\n",
        "    .setDropout(0.5)\n",
        "    .setPo(0.005)\n",
        "    .setLr(0.001)\n",
        "    .setMaxEpochs(20)\n",
        "    .setValidationSplit(0.2)\n",
        "    .setRandomSeed(0)\n",
        "    .setVerbose(1)\n",
        "    .setEvaluationLogExtended(True)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXX20gBxWbHc"
      },
      "source": [
        "training_pipeline = Pipeline(stages=[embeddings, ner_tagger])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj3jxAaNWifE"
      },
      "source": [
        "# Start training (X)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3flTFgRlWknP"
      },
      "source": [
        "# Get trained model\n",
        "trained_model = training_pipeline.fit(train_dataset)\n",
        "# After this Annotation Lab saves the models, training logs, etc."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}