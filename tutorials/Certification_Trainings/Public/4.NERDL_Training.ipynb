{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.NERDL_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sXatvRX899i0"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jOkfgBXDwxhz"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/4.NERDL_Training.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HCIg1pQpelJS"
      },
      "source": [
        "# 4. Named Entity Recognition (NER) DL Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JryP7HLODLnc",
        "colab_type": "text"
      },
      "source": [
        "#### Relevant blogpost: https://towardsdatascience.com/named-entity-recognition-ner-with-bert-in-spark-nlp-874df20d1d77"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HDH5i1coCgGJ"
      },
      "source": [
        "## Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-iCWzZ2NCZ0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "327a1958-b344-4f75-e628-b1b1725d6fba"
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed -q pyspark==2.4.4\n",
        "! pip install --ignore-installed -q spark-nlp==2.5.4"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_252\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
            "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 62kB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 46.9MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 133kB 5.4MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8DFCYTaDC1qZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "254ebe29-6965-4ef4-b9fb-a42b8d54b24d"
      },
      "source": [
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start() # for GPU training >> sparknlp.start(gpu = True) # for Spark 2.3 =>> sparknlp.start(spark23 = True)\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "\n",
        "print(\"Apache Spark version:\", spark.version)\n",
        "\n",
        "spark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version 2.5.4\n",
            "Apache Spark version: 2.4.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://8e34fba49688:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v2.4.4</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f21a8837208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YG1zLzzLEbyI"
      },
      "source": [
        "## CoNLL Data Prep "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MSg4fdlHD6x6",
        "colab": {}
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/conll2003/eng.train\n",
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/conll2003/eng.testa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C1Mn-tuqEofp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "8bb81e4e-119c-4002-e7bd-3685ce2c31ae"
      },
      "source": [
        "with open(\"eng.train\") as f:\n",
        "    train_txt =f.read()\n",
        "\n",
        "print (train_txt[:500])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-DOCSTART- -X- -X- O\n",
            "\n",
            "EU NNP B-NP B-ORG\n",
            "rejects VBZ B-VP O\n",
            "German JJ B-NP B-MISC\n",
            "call NN I-NP O\n",
            "to TO B-VP O\n",
            "boycott VB I-VP O\n",
            "British JJ B-NP B-MISC\n",
            "lamb NN I-NP O\n",
            ". . O O\n",
            "\n",
            "Peter NNP B-NP B-PER\n",
            "Blackburn NNP I-NP I-PER\n",
            "\n",
            "BRUSSELS NNP B-NP B-LOC\n",
            "1996-08-22 CD I-NP O\n",
            "\n",
            "The DT B-NP O\n",
            "European NNP I-NP B-ORG\n",
            "Commission NNP I-NP I-ORG\n",
            "said VBD B-VP O\n",
            "on IN B-PP O\n",
            "Thursday NNP B-NP O\n",
            "it PRP B-NP O\n",
            "disagreed VBD B-VP O\n",
            "with IN B-PP O\n",
            "German JJ B-NP B-MISC\n",
            "advice NN I-NP O\n",
            "to TO B-PP O\n",
            "consumers NNS B-NP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wG9RpnKCFffi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "55c29d48-a098-4559-e075-047c1695e8dc"
      },
      "source": [
        "from sparknlp.training import CoNLL\n",
        "\n",
        "training_data = CoNLL().readDataset(spark, './eng.train')\n",
        "\n",
        "training_data.show(3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|EU rejects German...|[[document, 0, 47...|[[document, 0, 47...|[[token, 0, 1, EU...|[[pos, 0, 1, NNP,...|[[named_entity, 0...|\n",
            "|     Peter Blackburn|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 4, Pe...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
            "| BRUSSELS 1996-08-22|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, BR...|[[pos, 0, 7, NNP,...|[[named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oUucp2eIGmh1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "895c4eb3-7092-4b23-d4c5-a6ae935a7a81"
      },
      "source": [
        "training_data.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- text: string (nullable = true)\n",
            " |-- document: array (nullable = false)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- sentence: array (nullable = false)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token: array (nullable = false)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- pos: array (nullable = false)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- label: array (nullable = false)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ho2JANGXFtbi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a793e4a-9995-4837-be20-8fa23f94f36f"
      },
      "source": [
        "training_data.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14041"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "94A1JedtFpDp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "3defd229-d32a-4ae8-fa69-7817e919fde1"
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "training_data.select(F.explode(F.arrays_zip('token.result', 'pos.result',  'label.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
        "        F.expr(\"cols['1']\").alias(\"pos\"),\n",
        "        F.expr(\"cols['2']\").alias(\"ner_label\")).show(truncate=50)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+---+---------+\n",
            "|     token|pos|ner_label|\n",
            "+----------+---+---------+\n",
            "|        EU|NNP|    B-ORG|\n",
            "|   rejects|VBZ|        O|\n",
            "|    German| JJ|   B-MISC|\n",
            "|      call| NN|        O|\n",
            "|        to| TO|        O|\n",
            "|   boycott| VB|        O|\n",
            "|   British| JJ|   B-MISC|\n",
            "|      lamb| NN|        O|\n",
            "|         .|  .|        O|\n",
            "|     Peter|NNP|    B-PER|\n",
            "| Blackburn|NNP|    I-PER|\n",
            "|  BRUSSELS|NNP|    B-LOC|\n",
            "|1996-08-22| CD|        O|\n",
            "|       The| DT|        O|\n",
            "|  European|NNP|    B-ORG|\n",
            "|Commission|NNP|    I-ORG|\n",
            "|      said|VBD|        O|\n",
            "|        on| IN|        O|\n",
            "|  Thursday|NNP|        O|\n",
            "|        it|PRP|        O|\n",
            "+----------+---+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "puWWnmUbGFVh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5549ab88-e926-4b79-aa15-fae9ac014686"
      },
      "source": [
        "\n",
        "training_data.select(F.explode(F.arrays_zip('token.result','label.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
        "        F.expr(\"cols['1']\").alias(\"ground_truth\")).groupBy('ground_truth').count().orderBy('count', ascending=False).show(100,truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+------+\n",
            "|ground_truth|count |\n",
            "+------------+------+\n",
            "|O           |169578|\n",
            "|B-LOC       |7140  |\n",
            "|B-PER       |6600  |\n",
            "|B-ORG       |6321  |\n",
            "|I-PER       |4528  |\n",
            "|I-ORG       |3704  |\n",
            "|B-MISC      |3438  |\n",
            "|I-LOC       |1157  |\n",
            "|I-MISC      |1155  |\n",
            "+------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fw2p7DOwGZto",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b3de7ae5-4765-42f6-e0de-2f5cf12a12e5"
      },
      "source": [
        "# You can use any word embeddings you want (Glove, Elmo, Bert, custom etc.)\n",
        "\n",
        "glove_embeddings = WordEmbeddingsModel.pretrained('glove_100d')\\\n",
        "          .setInputCols([\"document\", \"token\"])\\\n",
        "          .setOutputCol(\"embeddings\")\n",
        "    "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlRN1IJDENHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ner_logs"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8NFG_NK6G67o",
        "colab": {}
      },
      "source": [
        "nerTagger = NerDLApproach()\\\n",
        "  .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
        "  .setLabelColumn(\"label\")\\\n",
        "  .setOutputCol(\"ner\")\\\n",
        "  .setMaxEpochs(1)\\\n",
        "  .setLr(0.003)\\\n",
        "  .setPo(0.005)\\\n",
        "  .setBatchSize(32)\\\n",
        "  .setRandomSeed(0)\\\n",
        "  .setVerbose(1)\\\n",
        "  .setValidationSplit(0.2)\\\n",
        "  .setEvaluationLogExtended(True) \\\n",
        "  .setEnableOutputLogs(True)\\\n",
        "  .setIncludeConfidence(True)\\\n",
        "  .setOutputLogsPath('ner_logs') # if not set, logs will be written to ~/annotator_logs\n",
        "\n",
        "ner_pipeline = Pipeline(stages=[\n",
        "          glove_embeddings,\n",
        "          nerTagger\n",
        " ])\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1fggBlAjQoTl"
      },
      "source": [
        "### Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-cmPOQx6Gti6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a528f0e4-44eb-4615-f316-0fc49fe9d4be"
      },
      "source": [
        "%%time\n",
        "\n",
        "ner_model = ner_pipeline.fit(training_data)\n",
        "\n",
        "# 1 epoch takes around 2.5 min with batch size=32\n",
        "# if you get an error for incompatible TF graph, use 4.1 NerDL-Graph.ipynb notebook to create a graph (or see the bottom cell of this notebook)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 51.2 ms, sys: 8.37 ms, total: 59.5 ms\n",
            "Wall time: 2min 39s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zFXJ760TMK9t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ebb24ef7-bece-498b-9f37-c0bd5d4dabb7"
      },
      "source": [
        "#! cd ~/annotator_logs && ls -lt\n",
        "!cd ner_logs && ls -lt"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8\n",
            "-rw-r--r-- 1 root root 2026 Jul 27 11:53 NerDLApproach_c4218a4c7552.log\n",
            "-rw-r--r-- 1 root root  953 Jul 27 11:43 NerDLApproach_d64e2492a9d5.log\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwGTRKmBGIW8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "23565b42-48ff-49b3-a5ba-d81a6a98d07d"
      },
      "source": [
        "!head -n 45 ner_logs/NerDLApproach_c4218a4c7552.log"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name of the selected graph: ner-dl/blstm_10_100_128_120.pb\n",
            "Training started - total epochs: 1 - lr: 0.003 - batch size: 32 - labels: 9 - chars: 84 - training examples: 11233\n",
            "\n",
            "\n",
            "Epoch 1/1 started, lr: 0.003, dataset size: 11233\n",
            "\n",
            "\n",
            "Epoch 1/1 - 129.30s - loss: 1100.4757 - batches: 354\n",
            "Quality on validation dataset (20.0%), validation examples = 2808\n",
            "time to finish evaluation: 11.26s\n",
            "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
            "B-LOC\t 1325\t 178\t 105\t 0.8815702\t 0.92657346\t 0.9035118\n",
            "I-ORG\t 540\t 84\t 244\t 0.86538464\t 0.68877554\t 0.7670455\n",
            "I-MISC\t 172\t 127\t 53\t 0.57525086\t 0.7644445\t 0.65648854\n",
            "I-LOC\t 222\t 206\t 25\t 0.5186916\t 0.8987854\t 0.6577778\n",
            "I-PER\t 872\t 57\t 14\t 0.9386437\t 0.98419863\t 0.9608816\n",
            "B-MISC\t 577\t 146\t 93\t 0.79806364\t 0.861194\t 0.82842785\n",
            "B-ORG\t 987\t 99\t 293\t 0.90883976\t 0.7710937\t 0.8343195\n",
            "B-PER\t 1267\t 141\t 41\t 0.89985794\t 0.96865445\t 0.9329897\n",
            "tp: 5962 fp: 1038 fn: 868 labels: 8\n",
            "Macro-average\t prec: 0.7982878, rec: 0.85796505, f1: 0.8270513\n",
            "Micro-average\t prec: 0.8517143, rec: 0.8729136, f1: 0.86218363\n",
            "Name of the selected graph: ner-dl/blstm_10_100_128_120.pb\n",
            "Training started - total epochs: 1 - lr: 0.003 - batch size: 32 - labels: 9 - chars: 84 - training examples: 11233\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eTA6w7csHSAo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "2c563e76-50dd-4695-805e-eaf43b0aaf2a"
      },
      "source": [
        "from sparknlp.training import CoNLL\n",
        "\n",
        "test_data = CoNLL().readDataset(spark, './eng.testa')\n",
        "\n",
        "test_data = glove_embeddings.transform(test_data)\n",
        "\n",
        "test_data.show(3)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|          embeddings|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|CRICKET - LEICEST...|[[document, 0, 64...|[[document, 0, 64...|[[token, 0, 6, CR...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|   LONDON 1996-08-30|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 5, LO...|[[pos, 0, 5, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "|West Indian all-r...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 3, We...|[[pos, 0, 3, NNP,...|[[named_entity, 0...|[[word_embeddings...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GQ04hU6VNzug",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "ebe4970c-5e06-4880-f390-25376d907234"
      },
      "source": [
        "predictions = ner_model.transform(test_data)\n",
        "predictions.show(3)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|          embeddings|                 ner|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|CRICKET - LEICEST...|[[document, 0, 64...|[[document, 0, 64...|[[token, 0, 6, CR...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|   LONDON 1996-08-30|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 5, LO...|[[pos, 0, 5, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "|West Indian all-r...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 3, We...|[[pos, 0, 3, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w7J-30jWOdWZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "7a4b2d73-8c03-4b2b-b001-4c0a7a90d3da"
      },
      "source": [
        "predictions.select('token.result','label.result','ner.result').show(3, truncate=50)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
            "|                                            result|                                            result|                                            result|\n",
            "+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
            "|[CRICKET, -, LEICESTERSHIRE, TAKE, OVER, AT, TO...|             [O, O, B-ORG, O, O, O, O, O, O, O, O]|             [O, O, B-ORG, O, O, O, O, O, O, O, O]|\n",
            "|                              [LONDON, 1996-08-30]|                                        [B-LOC, O]|                                        [B-LOC, O]|\n",
            "|[West, Indian, all-rounder, Phil, Simmons, took...|[B-MISC, I-MISC, O, B-PER, I-PER, O, O, O, O, O...|[B-MISC, I-MISC, O, B-PER, I-PER, O, O, O, O, O...|\n",
            "+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AgdnSdjtQkZW"
      },
      "source": [
        "### Test set evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bbyhDUFDN63V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "4a3c6f53-b59c-40b1-9d51-e970edc5165b"
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "predictions.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
        "        F.expr(\"cols['1']\").alias(\"ground_truth\"),\n",
        "        F.expr(\"cols['2']\").alias(\"prediction\")).show(truncate=False)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+------------+----------+\n",
            "|token         |ground_truth|prediction|\n",
            "+--------------+------------+----------+\n",
            "|CRICKET       |O           |O         |\n",
            "|-             |O           |O         |\n",
            "|LEICESTERSHIRE|B-ORG       |B-ORG     |\n",
            "|TAKE          |O           |O         |\n",
            "|OVER          |O           |O         |\n",
            "|AT            |O           |O         |\n",
            "|TOP           |O           |O         |\n",
            "|AFTER         |O           |O         |\n",
            "|INNINGS       |O           |O         |\n",
            "|VICTORY       |O           |O         |\n",
            "|.             |O           |O         |\n",
            "|LONDON        |B-LOC       |B-LOC     |\n",
            "|1996-08-30    |O           |O         |\n",
            "|West          |B-MISC      |B-MISC    |\n",
            "|Indian        |I-MISC      |I-MISC    |\n",
            "|all-rounder   |O           |O         |\n",
            "|Phil          |B-PER       |B-PER     |\n",
            "|Simmons       |I-PER       |I-PER     |\n",
            "|took          |O           |O         |\n",
            "|four          |O           |O         |\n",
            "+--------------+------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Up-eKXlzN-vx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "8cac6085-e490-4102-c036-8433a269dabf"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "preds_df = predictions.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
        "        F.expr(\"cols['1']\").alias(\"ground_truth\"),\n",
        "        F.expr(\"cols['2']\").alias(\"prediction\")).toPandas()\n",
        "\n",
        "\n",
        "print (classification_report(preds_df['ground_truth'], preds_df['prediction']))\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.90      0.93      0.91      1837\n",
            "      B-MISC       0.85      0.83      0.84       922\n",
            "       B-ORG       0.91      0.78      0.84      1341\n",
            "       B-PER       0.93      0.96      0.95      1842\n",
            "       I-LOC       0.47      0.91      0.62       257\n",
            "      I-MISC       0.65      0.70      0.67       346\n",
            "       I-ORG       0.89      0.57      0.69       751\n",
            "       I-PER       0.95      0.96      0.96      1307\n",
            "           O       0.99      1.00      0.99     42759\n",
            "\n",
            "    accuracy                           0.97     51362\n",
            "   macro avg       0.84      0.85      0.83     51362\n",
            "weighted avg       0.98      0.97      0.97     51362\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0sD2CU4HP-H",
        "colab_type": "text"
      },
      "source": [
        "### Entity level evaluation (strict eval)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpkUb1gyHOk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget  -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/utils/conll_eval.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpiIrbx5I8qI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ca2bcfc5-3fc1-48a9-f641-105d6fe0977e"
      },
      "source": [
        "import conll_eval\n",
        "\n",
        "metrics = conll_eval.evaluate(preds_df['ground_truth'].values, preds_df['prediction'].values)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processed 51362 tokens with 5942 phrases; found: 6083 phrases; correct: 5172.\n",
            "accuracy:  86.49%; (non-O)\n",
            "accuracy:  97.36%; precision:  85.02%; recall:  87.04%; FB1:  86.02\n",
            "              LOC: precision:  85.07%; recall:  93.36%; FB1:  89.02  2016\n",
            "             MISC: precision:  76.88%; recall:  80.04%; FB1:  78.43  960\n",
            "              ORG: precision:  82.16%; recall:  73.15%; FB1:  77.40  1194\n",
            "              PER: precision:  90.85%; recall:  94.35%; FB1:  92.57  1913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ0jme54KDyC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67231f8a-7d61-4ba9-f993-55e8e7cd0bca"
      },
      "source": [
        "# micro, macro, avg\n",
        "metrics[0]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(85.02383692257109, 87.0414002019522, 86.02079002079002)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMZu0ottJkmn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "df8b3c4d-269a-4cdf-c6b3-38e072c5d284"
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(metrics[1], columns=['entity','precision','recall','f1','support'])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entity</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LOC</td>\n",
              "      <td>85.069444</td>\n",
              "      <td>93.358737</td>\n",
              "      <td>89.021542</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MISC</td>\n",
              "      <td>76.875000</td>\n",
              "      <td>80.043384</td>\n",
              "      <td>78.427205</td>\n",
              "      <td>960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ORG</td>\n",
              "      <td>82.160804</td>\n",
              "      <td>73.154362</td>\n",
              "      <td>77.396450</td>\n",
              "      <td>1194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PER</td>\n",
              "      <td>90.852065</td>\n",
              "      <td>94.353963</td>\n",
              "      <td>92.569907</td>\n",
              "      <td>1913</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  entity  precision     recall         f1  support\n",
              "0    LOC  85.069444  93.358737  89.021542     2016\n",
              "1   MISC  76.875000  80.043384  78.427205      960\n",
              "2    ORG  82.160804  73.154362  77.396450     1194\n",
              "3    PER  90.852065  94.353963  92.569907     1913"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "riQTP4wuQfVf"
      },
      "source": [
        "### Splitting dataset into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iB_h1GnJQi1W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2f3e5716-98be-45ab-a103-74ccac37a623"
      },
      "source": [
        "from sparknlp.training import CoNLL\n",
        "\n",
        "conll_data = CoNLL().readDataset(spark, './eng.train')\n",
        "\n",
        "(training_data, test_data) = conll_data.randomSplit([0.7, 0.3], seed = 100)\n",
        "\n",
        "print(\"Training Dataset Count: \" + str(training_data.count()))\n",
        "print(\"Test Dataset Count: \" + str(test_data.count()))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Dataset Count: 9938\n",
            "Test Dataset Count: 4103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP9r0CaSLNPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove_embeddings.transform(test_data).write.parquet('ner_dl_test.parquet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q8tCZbQyQ9QO",
        "colab": {}
      },
      "source": [
        "nerTagger = NerDLApproach()\\\n",
        "  .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
        "  .setLabelColumn(\"label\")\\\n",
        "  .setOutputCol(\"ner\")\\\n",
        "  .setMaxEpochs(1)\\\n",
        "  .setLr(0.003)\\\n",
        "  .setPo(0.005)\\\n",
        "  .setBatchSize(32)\\\n",
        "  .setRandomSeed(0)\\\n",
        "  .setVerbose(1)\\\n",
        "  .setValidationSplit(0.2)\\\n",
        "  .setEvaluationLogExtended(True) \\\n",
        "  .setEnableOutputLogs(True)\\\n",
        "  .setIncludeConfidence(True)\\\n",
        "  .setTestDataset('ner_dl_test.parquet')\\\n",
        "  .setOutputLogsPath('ner_logs') # if not set, logs will be written to ~/annotator_logs\n",
        "\n",
        "ner_pipeline = Pipeline(stages=[\n",
        "          glove_embeddings,\n",
        "          nerTagger\n",
        " ])\n",
        "\n",
        "\n",
        "ner_model = ner_pipeline.fit(training_data)\n",
        "\n",
        "test_data = glove_embeddings.transform(test_data)\n",
        "\n",
        "predictions = ner_model.transform(test_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WuJ5YZ9sXU13"
      },
      "source": [
        "### Saving the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KBcoOwvwXV8p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d1b4483-3640-452e-ec7a-1b3be2c131f8"
      },
      "source": [
        "ner_model.stages"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[WORD_EMBEDDINGS_MODEL_48cffc8b9a76, NerDLModel_c4dee3b6842e]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gRLbhTh1XYo2",
        "colab": {}
      },
      "source": [
        "ner_model.stages[1].write().overwrite().save('NER_glove_20200727_e1_b32')"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k6B_m0HeXhvo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c12fddd4-bcda-402a-c1a7-2159acf9abc2"
      },
      "source": [
        "!ls -lt"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4044\n",
            "drwxr-xr-x 4 root root    4096 Jul 27 12:10 NER_glove_20200727_e1_b32\n",
            "drwxr-xr-x 2 root root    4096 Jul 27 12:06 __pycache__\n",
            "-rw-r--r-- 1 root root    7431 Jul 27 12:00 conll_eval.py\n",
            "drwxr-xr-x 2 root root    4096 Jul 27 11:56 ner_logs\n",
            "-rw-r--r-- 1 root root  827443 Jul 27 11:36 eng.testa\n",
            "-rw-r--r-- 1 root root 3283420 Jul 27 11:36 eng.train\n",
            "drwxr-xr-x 1 root root    4096 Jul 10 16:29 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gK0rbohHRNmG"
      },
      "source": [
        "## Prediction Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XCLEQcCeQ8pn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "dedcd942-415a-4414-a56a-3e80d7943d62"
      },
      "source": [
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentence = SentenceDetector()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentence')\n",
        "\n",
        "token = Tokenizer()\\\n",
        "    .setInputCols(['sentence'])\\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "glove_embeddings = WordEmbeddingsModel.pretrained('glove_100d')\\\n",
        "          .setInputCols([\"document\", \"token\"])\\\n",
        "          .setOutputCol(\"embeddings\")\n",
        "    \n",
        "loaded_ner_model = NerDLModel.load(\"NER_glove_20200727_e1_b32\")\\\n",
        " .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
        " .setOutputCol(\"ner\")\n",
        "\n",
        "converter = NerConverter()\\\n",
        "  .setInputCols([\"document\", \"token\", \"ner\"])\\\n",
        "  .setOutputCol(\"ner_span\")\n",
        "\n",
        "ner_prediction_pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        sentence,\n",
        "        token,\n",
        "        glove_embeddings,\n",
        "        loaded_ner_model,\n",
        "        converter])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gsokdubdX1vE",
        "colab": {}
      },
      "source": [
        "empty_data = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "\n",
        "prediction_model = ner_prediction_pipeline.fit(empty_data)\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rR8b0tQlX7E8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d6e28274-4af3-48d1-a47d-02cc78ec1023"
      },
      "source": [
        "text = \"Peter Parker is a nice guy and lives in New York.\"\n",
        "\n",
        "sample_data = spark.createDataFrame([[text]]).toDF(\"text\")\n",
        "\n",
        "sample_data.show()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|                text|\n",
            "+--------------------+\n",
            "|Peter Parker is a...|\n",
            "+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WdeKg30uX_rk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7146f5a4-e51e-45cc-f284-788ab984988e"
      },
      "source": [
        "\n",
        "preds = prediction_model.transform(sample_data)\n",
        "\n",
        "preds.select(F.explode(F.arrays_zip(\"ner_span.result\",\"ner_span.metadata\")).alias(\"entities\")) \\\n",
        ".select(F.expr(\"entities['0']\").alias(\"chunk\"),\n",
        "        F.expr(\"entities['1'].entity\").alias(\"entity\")).show(truncate=False)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+------+\n",
            "|chunk       |entity|\n",
            "+------------+------+\n",
            "|Peter Parker|PER   |\n",
            "|New York    |LOC   |\n",
            "+------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UG6eBHQZYIhb",
        "colab": {}
      },
      "source": [
        "from sparknlp.base import LightPipeline\n",
        "\n",
        "light_model = LightPipeline(prediction_model)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7Hr5gtKbYLOW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "58f24351-a63c-4658-8b41-375b65c917e8"
      },
      "source": [
        "text = \"Peter Parker is a nice guy and lives in New York.\"\n",
        "\n",
        "result = light_model.annotate(text)\n",
        "\n",
        "list(zip(result['token'], result['ner']))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Peter', 'B-PER'),\n",
              " ('Parker', 'I-PER'),\n",
              " ('is', 'O'),\n",
              " ('a', 'O'),\n",
              " ('nice', 'O'),\n",
              " ('guy', 'O'),\n",
              " ('and', 'O'),\n",
              " ('lives', 'O'),\n",
              " ('in', 'O'),\n",
              " ('New', 'B-LOC'),\n",
              " ('York', 'I-LOC'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OO4xKzhIZEDc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "a747be83-d457-46d9-fd91-75b92f6d7a6b"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "result = light_model.fullAnnotate(text)\n",
        "\n",
        "ner_df= pd.DataFrame([(int(x.metadata['sentence']), x.result, x.begin, x.end, y.result) for x,y in zip(result[0][\"token\"], result[0][\"ner\"])], \n",
        "                      columns=['sent_id','token','start','end','ner'])\n",
        "ner_df"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent_id</th>\n",
              "      <th>token</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>ner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Peter</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>B-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Parker</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>I-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>is</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>nice</td>\n",
              "      <td>18</td>\n",
              "      <td>21</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>guy</td>\n",
              "      <td>23</td>\n",
              "      <td>25</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>and</td>\n",
              "      <td>27</td>\n",
              "      <td>29</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>lives</td>\n",
              "      <td>31</td>\n",
              "      <td>35</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>in</td>\n",
              "      <td>37</td>\n",
              "      <td>38</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>New</td>\n",
              "      <td>40</td>\n",
              "      <td>42</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>York</td>\n",
              "      <td>44</td>\n",
              "      <td>47</td>\n",
              "      <td>I-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>.</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sent_id   token  start  end    ner\n",
              "0         0   Peter      0    4  B-PER\n",
              "1         0  Parker      6   11  I-PER\n",
              "2         0      is     13   14      O\n",
              "3         0       a     16   16      O\n",
              "4         0    nice     18   21      O\n",
              "5         0     guy     23   25      O\n",
              "6         0     and     27   29      O\n",
              "7         0   lives     31   35      O\n",
              "8         0      in     37   38      O\n",
              "9         0     New     40   42  B-LOC\n",
              "10        0    York     44   47  I-LOC\n",
              "11        0       .     48   48      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eS-7yJLYXUZv"
      },
      "source": [
        "# creating your own CoNLL dataset¶\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "weM4V7QKX6es",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "8081569c-959d-434b-e661-770a3ccf036a"
      },
      "source": [
        "import json\n",
        "import os\n",
        "from pyspark.ml import Pipeline\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "def get_ann_pipeline ():\n",
        "    \n",
        "    document_assembler = DocumentAssembler() \\\n",
        "        .setInputCol(\"text\")\\\n",
        "        .setOutputCol('document')\n",
        "\n",
        "    tokenizer = Tokenizer() \\\n",
        "        .setInputCols([\"sentence\"]) \\\n",
        "        .setOutputCol(\"token\")\n",
        "\n",
        "    pos = PerceptronModel.pretrained() \\\n",
        "              .setInputCols([\"sentence\", \"token\"]) \\\n",
        "              .setOutputCol(\"pos\")\n",
        "    \n",
        "    embeddings = WordEmbeddingsModel.pretrained()\\\n",
        "          .setInputCols([\"sentence\", \"token\"])\\\n",
        "          .setOutputCol(\"embeddings\")\n",
        "\n",
        "    ner_model = NerDLModel.pretrained() \\\n",
        "          .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "          .setOutputCol(\"ner\")\n",
        "\n",
        "    ner_converter = NerConverter()\\\n",
        "      .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
        "      .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "    ner_pipeline = Pipeline(\n",
        "        stages = [\n",
        "            document_assembler,\n",
        "            sentence,\n",
        "            tokenizer,\n",
        "            pos,\n",
        "            embeddings,\n",
        "            ner_model,\n",
        "            ner_converter\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "    ner_pipelineFit = ner_pipeline.fit(empty_data)\n",
        "\n",
        "    ner_lp_pipeline = LightPipeline(ner_pipelineFit)\n",
        "\n",
        "    print (\"Spark NLP NER lightpipeline is created\")\n",
        "\n",
        "    return ner_lp_pipeline\n",
        "\n",
        "\n",
        "conll_pipeline = get_ann_pipeline ()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pos_anc download started this may take some time.\n",
            "Approximate size to download 4.3 MB\n",
            "[OK!]\n",
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n",
            "ner_dl download started this may take some time.\n",
            "Approximate size to download 13.6 MB\n",
            "[OK!]\n",
            "Spark NLP NER lightpipeline is created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bl0K3XvFb3WO",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nk3NSf6FbZJb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "a31530d7-6e85-4bb8-af03-b44c4df8ac1c"
      },
      "source": [
        "\n",
        "sentences = [\"Peter Parker is a nice guy and lives in New York.\",\n",
        "\"He is also helping people around the world.\"]\n",
        "\n",
        "conll_lines=''\n",
        "\n",
        "for sentence in sentences:\n",
        "\n",
        "  parsed = conll_pipeline.annotate (sentence)\n",
        "\n",
        "  for token, pos, ner in zip(parsed['token'],parsed['pos'],parsed['ner']):\n",
        "\n",
        "      conll_lines += \"{} {} {} {}\\n\".format(token, pos, pos, ner)\n",
        "\n",
        "  conll_lines += '\\n'\n",
        "\n",
        "\n",
        "print(conll_lines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Peter NNP NNP B-PER\n",
            "Parker NNP NNP I-PER\n",
            "is VBZ VBZ O\n",
            "a DT DT O\n",
            "nice JJ JJ O\n",
            "guy NN NN O\n",
            "and CC CC O\n",
            "lives NNS NNS O\n",
            "in IN IN O\n",
            "New NNP NNP B-LOC\n",
            "York NNP NNP I-LOC\n",
            ". . . O\n",
            "\n",
            "He PRP PRP O\n",
            "is VBZ VBZ O\n",
            "also RB RB O\n",
            "helping VBG VBG O\n",
            "people NNS NNS O\n",
            "around IN IN O\n",
            "the DT DT O\n",
            "world NN NN O\n",
            ". . . O\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFT4QsnnFO5H",
        "colab_type": "text"
      },
      "source": [
        "# NerDL Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6_bsjItFSSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/training/english/dl-ner/nerdl-graph/create_graph.py\n",
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/training/english/dl-ner/nerdl-graph/dataset_encoder.py\n",
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/training/english/dl-ner/nerdl-graph/ner_model.py\n",
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/training/english/dl-ner/nerdl-graph/ner_model_saver.py\n",
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/training/english/dl-ner/nerdl-graph/sentence_grouper.py\n",
        "\n",
        "!pip -q install tensorflow==1.15.0\n",
        "\n",
        "import create_graph\n",
        "\n",
        "ntags = 19 # number of labels\n",
        "embeddings_dim = 100\n",
        "nchars =100\n",
        "\n",
        "create_graph.create_graph(ntags, embeddings_dim, nchars)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}