{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "InUmp9hn1vX6"
   },
   "source": [
    "# Spark NLP Clinical Assertion Model TF Graph Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1-Kle9jF1mDx"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2_1.Clinical_Assertion_Graph_Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zXxiaFIe1uoX"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c2pzWsg2yV2W"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "   BiLSTM on I2b2 Assertion Status Classification\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from math import ceil\n",
    "\n",
    "class AssertionModel:\n",
    "\n",
    "    def __init__(self, seq_max_len, feat_size, n_classes, device='/cpu:0'):\n",
    "        tf.reset_default_graph()\n",
    "        self._device = device\n",
    "        with tf.device(device):\n",
    "            self.x = tf.placeholder(\"float\", [None, seq_max_len, feat_size], 'word_repr/word_embeddings')\n",
    "            self.y = tf.placeholder(\"float\", [None, n_classes], 'training/labels')\n",
    "\n",
    "            # A placeholder for indicating each sentence length\n",
    "            self.seqlen = tf.placeholder(tf.int32, [None], 'word_repr/sentence_lengths')\n",
    "            self.n_classes = n_classes\n",
    "\n",
    "            self.output_keep_prob = tf.placeholder_with_default(tf.constant(1.0, dtype=tf.float32), (), 'training/dropout')\n",
    "            self.rate = tf.placeholder_with_default(tf.constant(.02, dtype=tf.float32), (), 'training/lr')\n",
    "\n",
    "            # per_process_gpu_memory_fraction=0.99, \n",
    "            gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "            config_proto = tf.ConfigProto(log_device_placement=True, allow_soft_placement=True, gpu_options=gpu_options)\n",
    "            self.sess = tf.Session(config=config_proto)\n",
    "\n",
    "    def fully_connected_layer(self, input_data, output_dim, activation_func=None):\n",
    "        with tf.device(self._device):\n",
    "            input_dim = int(input_data.get_shape()[1])\n",
    "            W = tf.Variable(tf.random_normal([input_dim, output_dim]))\n",
    "            b = tf.Variable(tf.random_normal([output_dim]))\n",
    "            if activation_func:\n",
    "                return activation_func(tf.matmul(input_data, W) + b)\n",
    "            else:\n",
    "                return tf.add(tf.matmul(input_data, W), b, name='output')\n",
    "\n",
    "    def add_bidirectional_lstm(self, n_hidden=30, num_layers=3):\n",
    "        with tf.device(self._device):\n",
    "            seq_max_len = self.x.get_shape()[1]\n",
    "\n",
    "            fw_cells = []\n",
    "            bw_cells = []\n",
    "\n",
    "            for layer_num in range(1, num_layers + 1):\n",
    "                # Define a lstm cell with tensorflow  -  Forward direction cell\n",
    "                lstm_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0, name='fw' + str(layer_num))\n",
    "                lstm_fw_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_fw_cell, output_keep_prob=self.output_keep_prob)\n",
    "                fw_cells.append(lstm_fw_cell)\n",
    "\n",
    "                # Backward direction cell\n",
    "                lstm_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0, name='bw' + str(layer_num))\n",
    "                lstm_bw_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_bw_cell, output_keep_prob=self.output_keep_prob)\n",
    "                bw_cells.append(lstm_bw_cell)\n",
    "\n",
    "            # Get lstm cell output, providing 'sequence_length' will perform dynamic\n",
    "            # calculation.\n",
    "            outputs, _, _ = \\\n",
    "                tf.contrib.rnn.stack_bidirectional_dynamic_rnn(fw_cells, bw_cells,\n",
    "                                                self.x, dtype=tf.float32,\n",
    "                                                sequence_length=self.seqlen)\n",
    "\n",
    "            # Hack to build the indexing and retrieve the right output.\n",
    "            batchSize = tf.shape(outputs)[0]\n",
    "\n",
    "            # Start indices for each sample\n",
    "            index = tf.range(0, batchSize) * seq_max_len + (self.seqlen - 1)\n",
    "\n",
    "            # Index of the last output for the variable length sequence\n",
    "            outputs = tf.gather(tf.reshape(outputs, [-1, n_hidden * 2]), index)\n",
    "\n",
    "            # Linear activation, using outputs computed above\n",
    "            self.bi_lstm = self.fully_connected_layer(outputs, self.n_classes)\n",
    "\n",
    "            self.output_label = tf.argmax(self.bi_lstm, 1, name=\"output_label\")\n",
    "\n",
    "            # match_count reflects the number of matches in a batch\n",
    "            correct_pred = tf.equal(tf.argmax(self.bi_lstm, 1), tf.argmax(self.y, 1))\n",
    "            self.match_count = tf.reduce_sum(tf.cast(correct_pred, tf.float32), name='training/match_count')\n",
    "\n",
    "    def add_optimizer(self):\n",
    "        with tf.device(self._device):\n",
    "            with tf.variable_scope(\"training\") as scope:\n",
    "                pred = self.bi_lstm\n",
    "\n",
    "                # Define loss and optimizer\n",
    "                cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=self.y), name=\"loss\")\n",
    "                self.optimizer = tf.train.AdamOptimizer(learning_rate=self.rate).minimize(cost)\n",
    "\n",
    "            # Initialize the variables (i.e. assign their default value)\n",
    "            self.init = tf.global_variables_initializer()\n",
    "\n",
    "    def train(self, trainset, testset, epochs, batch_size=64, learning_rate=0.01, dropout=0.15,  epoch_acc=7):\n",
    "        # Run the initializer\n",
    "        with tf.device(self._device):\n",
    "            self.sess.run(self.init)\n",
    "\n",
    "            num_batches = ceil(trainset.size()[0] / batch_size)\n",
    "            rate = learning_rate\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                for batch in range(1, num_batches + 1):\n",
    "                    batch_x, batch_y, batch_seqlen = trainset.next(batch_size)\n",
    "                    # Run optimization op (backprop)\n",
    "                    self.sess.run(self.optimizer, feed_dict={self.x: batch_x, self.y: batch_y,\n",
    "                                                   self.seqlen: batch_seqlen, self.output_keep_prob: 1 - dropout,\n",
    "                                                   self.rate: rate})\n",
    "                if epoch > epoch_acc:\n",
    "                    print('epoch # %d' % epoch, 'accuracy: %f' % self.calc_accuracy(testset, batch_size))\n",
    "                    rate *= .99\n",
    "                    #print(self.confusion_matrix(testset, sess, batch_size))\n",
    "                else:\n",
    "                    print('epoch # %d' % epoch)\n",
    "\n",
    "            print(\"Optimization Finished!\")\n",
    "\n",
    "    def calc_accuracy(self, dataset, batch_size):\n",
    "\n",
    "        ''' Calculate accuracy on dataset '''\n",
    "        \n",
    "        with tf.device(self._device):\n",
    "\n",
    "            assert (dataset.batch_id == 0)\n",
    "            n_test_batches = ceil(dataset.size()[0] / batch_size)\n",
    "            global_matches = 0\n",
    "\n",
    "            for batch in range(1, n_test_batches + 1):\n",
    "                batch_x, batch_y, batch_seqlen = dataset.next(batch_size)\n",
    "                global_matches += self.sess.run(self.match_count, feed_dict={self.x: batch_x, self.y:batch_y, self.seqlen: batch_seqlen})\n",
    "\n",
    "            return global_matches / float(dataset.size()[0])\n",
    "\n",
    "    def confusion_matrix(self, dataset, sess, batch_size):\n",
    "        with tf.device(self._device):\n",
    "            assert(dataset.batch_id == 0)\n",
    "\n",
    "            n_test_batches = ceil(dataset.size()[0] / batch_size)\n",
    "            predicted = list()\n",
    "\n",
    "            # obtain index of largest\n",
    "            correct = [one_hot_label.index(max(one_hot_label)) for one_hot_label in dataset.labels]\n",
    "\n",
    "            for batch in range(1, n_test_batches + 1):\n",
    "                batch_x, batch_y, batch_seqlen = dataset.next(batch_size)\n",
    "                batch_predictions = sess.run(self.bi_lstm, feed_dict={self.x: batch_x, self.seqlen: batch_seqlen})\n",
    "                predicted += [pred.argmax() for pred in batch_predictions]\n",
    "\n",
    "            # lengths should match\n",
    "            assert(len(predicted) == len(correct))\n",
    "\n",
    "            # infer all possible class labels\n",
    "            labels = set(correct)\n",
    "            from collections import defaultdict\n",
    "            matrix = {k: defaultdict(int) for k in labels}\n",
    "\n",
    "            for g, p in zip(correct, predicted):\n",
    "                matrix[g][p] += 1\n",
    "\n",
    "            # sanity check, confusion matrix contains as many elements as they were used during prediction\n",
    "            matrix_size = sum([element for idx in matrix for element in matrix[idx].values()])\n",
    "            assert(len(predicted) == matrix_size)\n",
    "\n",
    "            # Check to make sure score computation is correct\n",
    "            # from sklearn.metrics import f1_score\n",
    "            # print(f1_score(correct, predicted, average='micro'))\n",
    "\n",
    "            return matrix\n",
    "\n",
    "    def persist_graph(self, filename):\n",
    "        # Add ops to save and restore all the variables (not used here but we need it in the graph).\n",
    "        with tf.device(self._device):\n",
    "            tf.train.Saver()\n",
    "            tf.train.write_graph(self.sess.graph, './', filename, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "colab_type": "code",
    "id": "U-JWcRSWykbS",
    "outputId": "cbc6fd73-c6d5-4afc-a1d4-8966f1161430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-3-3f657bceb931>:47: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/rnn/python/ops/rnn.py:239: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "def create_graph(max_seq_len, feat_size, n_classes, filename):\n",
    "\n",
    "    # instantiate model\n",
    "    model = AssertionModel(max_seq_len, feat_size=feat_size + 10, n_classes=n_classes, device='/cpu:0')\n",
    "\n",
    "    # Network Parameters\n",
    "    model.add_bidirectional_lstm(n_hidden=34)\n",
    "    model.add_optimizer()\n",
    "\n",
    "    # Persist graph\n",
    "    model.persist_graph(filename)\n",
    "\n",
    "\n",
    "# i2b2\n",
    "max_seq_len = 250\n",
    "feat_size = 200\n",
    "n_classes = 7\n",
    "create_graph(max_seq_len, feat_size, n_classes, 'blstm_34_32_30_200_{}.pb'.format(n_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pLhHOz8Uy6nj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2.1.Clinical_Assertion_Graph_Generation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
