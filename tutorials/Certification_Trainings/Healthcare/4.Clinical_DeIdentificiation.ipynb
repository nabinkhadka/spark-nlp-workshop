{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I08sFJYCxR0Z"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LKI5K1wQrSe9"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/4.Clinical_DeIdentificiation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Niy3mZAjoayg"
   },
   "source": [
    "# Clinical Deidentification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "okhT7AcXxben"
   },
   "source": [
    "## Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I8Ytt2LLp2rj",
    "outputId": "6254856e-5398-427d-ad7b-bcc099122402"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('workshop_license_keys.json') as f_in:\n",
    "    license_keys = json.load(f_in)\n",
    "\n",
    "license_keys.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_BkrtwRnBcnw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'secret': 'xxx',\n",
       " 'SPARK_NLP_LICENSE': 'aaa',\n",
       " 'JSL_OCR_LICENSE': 'bbb',\n",
       " 'AWS_ACCESS_KEY_ID': 'ccc',\n",
       " 'AWS_SECRET_ACCESS_KEY': 'ddd',\n",
       " 'JSL_OCR_SECRET': 'eee'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template for license_key.json\n",
    "\n",
    "{\"secret\":\"xxx\",\n",
    "\"SPARK_NLP_LICENSE\": \"aaa\",\n",
    "\"JSL_OCR_LICENSE\": \"bbb\",\n",
    "\"AWS_ACCESS_KEY_ID\":\"ccc\",\n",
    "\"AWS_SECRET_ACCESS_KEY\":\"ddd\",\n",
    "\"JSL_OCR_SECRET\":\"eee\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "xy-mE2aVxZjl",
    "outputId": "d82c93e4-1561-47ad-b814-fbaabb46cdfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "openjdk version \"1.8.0_252\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
      "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.johnsnowlabs.com/caQsTuCU35\n",
      "Requirement already up-to-date: spark-nlp-jsl==2.5.3 in /home/alina/.local/lib/python3.6/site-packages (2.5.3)\n",
      "Requirement already satisfied, skipping upgrade: pyspark==2.4.4 in /home/alina/.local/lib/python3.6/site-packages (from spark-nlp-jsl==2.5.3) (2.4.4)\n",
      "Requirement already satisfied, skipping upgrade: spark-nlp==2.5.3 in /home/alina/.local/lib/python3.6/site-packages (from spark-nlp-jsl==2.5.3) (2.5.3)\n",
      "Requirement already satisfied, skipping upgrade: py4j==0.10.7 in /home/alina/.local/lib/python3.6/site-packages (from pyspark==2.4.4->spark-nlp-jsl==2.5.3) (0.10.7)\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n",
      "2.5.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Install java\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed -q pyspark==2.4.4\n",
    "\n",
    "secret = license_keys['secret']\n",
    "os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n",
    "os.environ['JSL_OCR_LICENSE'] = license_keys['JSL_OCR_LICENSE']\n",
    "os.environ['AWS_ACCESS_KEY_ID']= license_keys['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n",
    "\n",
    "! python3 -m pip install --upgrade spark-nlp-jsl==2.5.3  --extra-index-url https://pypi.johnsnowlabs.com/$secret\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip3 install --ignore-installed -q spark-nlp==2.5.3\n",
    "\n",
    "import sparknlp\n",
    "\n",
    "print (sparknlp.version())\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp_jsl\n",
    "\n",
    "\n",
    "\n",
    "def start(secret):\n",
    "    builder = SparkSession.builder \\\n",
    "        .appName(\"Spark NLP Licensed\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.memory\", \"1G\") \\\n",
    "        .config(\"spark.driver.host\",\"localhost\") \\\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "        .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.3\") \\\n",
    "        .config(\"spark.jars\", \"https://pypi.johnsnowlabs.com/\"+secret+\"/spark-nlp-jsl-2.5.3.jar\")\n",
    "      \n",
    "    return builder.getOrCreate()\n",
    "\n",
    "\n",
    "spark = start(secret) # if you want to start the session with custom params as in start function above\n",
    "# sparknlp_jsl.start(secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "colab_type": "code",
    "id": "V1wrGrq0GClP",
    "outputId": "eafce5ec-0a83-4f6f-8cd4-fb1f10d9fae7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP Licensed</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f226d9579e8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rFQifkFYihOc"
   },
   "source": [
    "# Deidentification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Protected Health Information: \n",
    "- individualâ€™s past, present, or future physical or mental health or condition\n",
    "- provision of health care to the individual\n",
    "- past, present, or future payment for the health care \n",
    "\n",
    "Protected health information includes many common identifiers (e.g., name, address, birth date, Social Security Number) when they can be associated with the health information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load NER pipeline to isentify protected entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ONMo7NWXU19B"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "import pyspark.sql.functions as F\n",
    "import string\n",
    "import numpy as np\n",
    "import sparknlp\n",
    "from sparknlp.util import *\n",
    "from sparknlp.pretrained import ResourceDownloader\n",
    "from pyspark.sql import functions as F\n",
    "from sparknlp_jsl.annotator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "qHzG7Wvhgcex",
    "outputId": "6ea42b81-47eb-4cf8-8610-801c3bb80907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_deid_large download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "from sparknlp_jsl.annotator import *\n",
    "\n",
    "documentAssembler = DocumentAssembler()\\\n",
    "  .setInputCol(\"text\")\\\n",
    "  .setOutputCol(\"document\")\n",
    "\n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "\n",
    "sentenceDetector = SentenceDetector()\\\n",
    "  .setInputCols([\"document\"])\\\n",
    "  .setOutputCol(\"sentence\")\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "  .setInputCols([\"sentence\"])\\\n",
    "  .setOutputCol(\"token\")\n",
    "\n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "\n",
    "word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "  .setInputCols([\"sentence\", \"token\"])\\\n",
    "  .setOutputCol(\"embeddings\")\n",
    "\n",
    "# NER model trained on n2c2 (de-identification and Heart Disease Risk Factors Challenge) datasets)\n",
    "\n",
    "clinical_ner = NerDLModel.pretrained(\"ner_deid_large\", \"en\", \"clinical/models\") \\\n",
    "  .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "  .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = NerConverterInternal()\\\n",
    "  .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
    "  .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[\n",
    "    documentAssembler, \n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    ner_converter])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained NER models extracts:\n",
    "\n",
    "- Name\n",
    "- Profession\n",
    "- Age\n",
    "- Date\n",
    "- Contact(Telephone numbers, FAX numbers, Email addresses)\n",
    "- Location (Address, City, Postal code, Hospital Name, Employment information)\n",
    "- Id (Social Security numbers, Medical record numbers, Internet protocol addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text ='''\n",
    "A . Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson , Ora MR . # 7194334 Date : 01/13/93 PCP : Oliveira , 25 month years-old , Record date : 2079-11-09 . Cocke County Baptist Hospital . 0295 Keats Street\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(spark.createDataFrame([[text]]).toDF(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result.select(F.explode(F.arrays_zip('token.result', 'ner.result')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "        F.expr(\"cols['1']\").alias(\"ner_label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|ner_label |count|\n",
      "+----------+-----+\n",
      "|O         |28   |\n",
      "|I-LOCATION|5    |\n",
      "|B-DATE    |3    |\n",
      "|B-NAME    |3    |\n",
      "|I-NAME    |3    |\n",
      "|B-LOCATION|2    |\n",
      "|B-ID      |1    |\n",
      "|B-AGE     |1    |\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.select(\"token\", \"ner_label\").groupBy('ner_label').count().orderBy('count', ascending=False).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check extracted sensetive entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+---------+\n",
      "|chunk                        |ner_label|\n",
      "+-----------------------------+---------+\n",
      "|2093-01-13                   |DATE     |\n",
      "|David Hale                   |NAME     |\n",
      "|Hendrickson , Ora            |NAME     |\n",
      "|7194334                      |ID       |\n",
      "|01/13/93                     |DATE     |\n",
      "|Oliveira                     |NAME     |\n",
      "|25                           |AGE      |\n",
      "|2079-11-09                   |DATE     |\n",
      "|Cocke County Baptist Hospital|LOCATION |\n",
      "|0295 Keats Street            |LOCATION |\n",
      "+-----------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "        F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the cases, where the model will skip some important entities, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text ='''\n",
    "Patient AIQING, 25 month years-old , born in Beijing, was transfered to the The Johns Hopkins Hospital. Phone number: (541) 754-3010. MSW 100009632582\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(spark.createDataFrame([[text]]).toDF(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+---------+\n",
      "|chunk                     |ner_label|\n",
      "+--------------------------+---------+\n",
      "|25                        |AGE      |\n",
      "|Beijing                   |LOCATION |\n",
      "|The Johns Hopkins Hospital|LOCATION |\n",
      "|(541) 754-3010            |CONTACT  |\n",
      "|100009632582              |ID       |\n",
      "+--------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df = result.select(F.explode(F.arrays_zip('token.result', 'ner.result')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "        F.expr(\"cols['1']\").alias(\"ner_label\"))\n",
    "\n",
    "result.select(F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "        F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these entities we can add a dictionary to the pipeline, by using **NerOverwriter()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "neroverwriter = NerOverwriter() \\\n",
    "    .setInputCols([\"ner\"]) \\\n",
    "    .setOutputCol(\"ner_overwrited\") \\\n",
    "    .setStopWords(['AIQING']) \\\n",
    "    .setNewResult(\"I-NAME\")\n",
    "\n",
    "ner_converter = NerConverterInternal()\\\n",
    "  .setInputCols([\"sentence\", \"token\", \"ner_overwrited\"])\\\n",
    "  .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[\n",
    "    documentAssembler, \n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    neroverwriter,\n",
    "    ner_converter])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the model after modification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(spark.createDataFrame([[text]]).toDF(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+---------+\n",
      "|chunk                     |ner_label|\n",
      "+--------------------------+---------+\n",
      "|AIQING                    |NAME     |\n",
      "|25                        |AGE      |\n",
      "|Beijing                   |LOCATION |\n",
      "|The Johns Hopkins Hospital|LOCATION |\n",
      "|(541) 754-3010            |CONTACT  |\n",
      "|100009632582              |ID       |\n",
      "+--------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df = result.select(F.explode(F.arrays_zip('token.result', 'ner.result')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "        F.expr(\"cols['1']\").alias(\"ner_label\"))\n",
    "\n",
    "result.select(F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "        F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, now name **AIQING** was identified correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excluding entities from deidentification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we need to leave some entities in the text, for example, if we want to analyze the frequency of the disease by the hospital. In this case, we need to use parameter **setWhiteList()** to modify NerChunk output. This parameter having using a list of entities type to deidentify as an input. So, if we want to leave the location in the list we need to remove this tag from the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_converter = NerConverterInternal()\\\n",
    "  .setInputCols([\"sentence\", \"token\", \"ner_overwrited\"])\\\n",
    "  .setOutputCol(\"ner_chunk\") \\\n",
    "  .setWhiteList(['NAME', 'PROFESSION', 'ID', 'AGE',\n",
    "               'DATE', 'CONTACT'])\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[\n",
    "    documentAssembler, \n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    neroverwriter,\n",
    "    ner_converter])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model_with_white_list = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_with_white_list = model_with_white_list.transform(spark.createDataFrame([[text]]).toDF(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+\n",
      "|chunk         |ner_label|\n",
      "+--------------+---------+\n",
      "|AIQING        |NAME     |\n",
      "|25            |AGE      |\n",
      "|(541) 754-3010|CONTACT  |\n",
      "|100009632582  |ID       |\n",
      "+--------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df = result.select(F.explode(F.arrays_zip('token.result', 'ner.result')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "        F.expr(\"cols['1']\").alias(\"ner_label\"))\n",
    "\n",
    "result_with_white_list.select(F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "        F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking and Obfuscation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace this enitites with Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "WaFe5bZzhEXT",
    "outputId": "d6a0f2e9-0a82-4f2a-8ee0-5c63503e3241"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deidentify_large download started this may take some time.\n",
      "Approximate size to download 188.1 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "deidentification = DeIdentificationModel.pretrained(\"deidentify_large\", \"en\", \"clinical/models\") \\\n",
    "      .setInputCols([\"sentence\", \"token\", \"ner_chunk\"]) \\\n",
    "      .setOutputCol(\"deidentified\") \\\n",
    "      .setMode(\"mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "deid_text = deidentification.transform(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>deidentified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patient AIQING, 25 month years-old , born in Beijing, was transfered to the The Johns Hopkins Hospital.</td>\n",
       "      <td>Patient &lt;NAME&gt;, &lt;AGE&gt; month years-old , born in &lt;LOCATION&gt;, was transfered to the &lt;LOCATION&gt;.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phone number: (541) 754-3010.</td>\n",
       "      <td>Phone number: &lt;CONTACT&gt;.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSW 100009632582</td>\n",
       "      <td>MSW &lt;ID&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  sentence                                                                                   deidentified\n",
       "0  Patient AIQING, 25 month years-old , born in Beijing, was transfered to the The Johns Hopkins Hospital.  Patient <NAME>, <AGE> month years-old , born in <LOCATION>, was transfered to the <LOCATION>.\n",
       "1  Phone number: (541) 754-3010.                                                                            Phone number: <CONTACT>.                                                                     \n",
       "2  MSW 100009632582                                                                                         MSW <ID>                                                                                     "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deid_text.select(F.explode(F.arrays_zip('sentence.result', 'deidentified.result')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"sentence\"), F.expr(\"cols['1']\").alias(\"deidentified\")).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use obfuscation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the obfuscation mode **DeIdentificationModel** will replace sensetive entities with random values of the same type. \n",
    "\n",
    "Will be replaced: \n",
    "- Name\n",
    "- Date\n",
    "- Location\n",
    "- Contacts\n",
    "- Profession\n",
    "\n",
    "Will be tagged:\n",
    "- Age\n",
    "- ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deidentify_large download started this may take some time.\n",
      "Approximate size to download 188.1 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "obfuscation = DeIdentificationModel.pretrained(\"deidentify_large\", \"en\", \"clinical/models\") \\\n",
    "      .setInputCols([\"sentence\", \"token\", \"ner_chunk\"]) \\\n",
    "      .setOutputCol(\"deidentified\") \\\n",
    "      .setMode(\"obfuscate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "obfusated_text = obfuscation.transform(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>deidentified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patient AIQING, 25 month years-old , born in Beijing, was transfered to the The Johns Hopkins Hospital.</td>\n",
       "      <td>Patient Tory, &lt;AGE&gt; month years-old , born in Gonvick, was transfered to the Grass Valley.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phone number: (541) 754-3010.</td>\n",
       "      <td>Phone number: (305)697-1817.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSW 100009632582</td>\n",
       "      <td>MSW &lt;ID&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  sentence                                                                                deidentified\n",
       "0  Patient AIQING, 25 month years-old , born in Beijing, was transfered to the The Johns Hopkins Hospital.  Patient Tory, <AGE> month years-old , born in Gonvick, was transfered to the Grass Valley.\n",
       "1  Phone number: (541) 754-3010.                                                                            Phone number: (305)697-1817.                                                              \n",
       "2  MSW 100009632582                                                                                         MSW <ID>                                                                                  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obfusated_text.select(F.explode(F.arrays_zip('sentence.result', 'deidentified.result')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"sentence\"), F.expr(\"cols['1']\").alias(\"deidentified\")).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use full pipeline in the Light model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "finisher = Finisher() \\\n",
    "    .setInputCols(\"deidentified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qhq7n1IahS_Y"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[\n",
    "    documentAssembler, \n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    neroverwriter,\n",
    "    ner_converter,\n",
    "    obfuscation,\n",
    "    finisher])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = pipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhtnLajzgNNb"
   },
   "outputs": [],
   "source": [
    "light_model = LightPipeline(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_sC_bn1Hhs9g"
   },
   "outputs": [],
   "source": [
    "text ='''\n",
    "A . Record date : 2093-01-13 , David Hale , M.D . , Name : Hendrickson , Ora MR . # 7194334 Date : 01-13-1993 PCP : Oliveira , 25 month years-old , Record date : 2079-11-09 . Cocke County Baptist Hospital . 0295 Keats Street\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "jbblkrvjEHn9",
    "outputId": "d11526e2-2f58-45b3-f415-aa451e85a174"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A .',\n",
       " 'Record date : 2093-03-06 , BUCK , M.D .',\n",
       " ', Name : VERONICA MR .',\n",
       " '# <ID> Date : 02-22-1993 PCP : GABRILA , <AGE> month years-old , Record date : 2079-12-19 .',\n",
       " 'Cocke County Baptist Hospital .',\n",
       " '<ID> Keats Street']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_text = light_model.annotate(text)\n",
    "annotated_text['deidentified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "0emrh9kBfRKf",
    "outputId": "206b3d00-6540-44ad-b4ea-287a2c00d06c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Record date : 2093-01-27, BRYANA, M.D. is Nannies, \\nName: TONY MR. # <ID> Date: (904)372-8017 PCP: Courtney.',\n",
       " 'Record date: 2080-01-01.',\n",
       " 'Cocke County Baptist Hospital.',\n",
       " '<ID> Keats Street.',\n",
       " 'This <AGE> male, presented with chest heaviness that started during a pick-up basketball game.',\n",
       " 'His past medical history was unremarkable.',\n",
       " 'He denied prior cardiac symptoms and suffered no chest trauma during the game.',\n",
       " 'His father had suffered an acute myocardial infarction at age',\n",
       " '<AGE>. The patient was a nonsmoker, did not drink alcohol, and denied recreational drug use.',\n",
       " 'He swallowed a tablet of aspirin before coming to the emergency room.',\n",
       " 'His blood pressure was 160/90 mm Hg, and his heart rate was 80 bpm.',\n",
       " 'Physical examination revealed no stigmata of Marfan syndrome.',\n",
       " 'The rest of his physical examination was normal.']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_text = '''Record date : 2093-01-13, David Hale, M.D. is manager, \n",
    "Name: Hendrickson, Ora MR. # 7194334 Date: 01-13-1993 PCP: Oliveira.\n",
    "Record date: 2079-11-09. Cocke County Baptist Hospital. 0295 Keats Street.\n",
    "This 17-yr-old male, presented with chest heaviness that started during a pick-up basketball game. His past medical history was unremarkable. He denied prior cardiac symptoms and suffered no chest trauma during the game. His father had suffered an acute myocardial infarction at age 38. The patient was a nonsmoker, did not drink alcohol, and denied recreational drug use. He swallowed a tablet of aspirin before coming to the emergency room. His blood pressure was 160/90 mm Hg, and his heart rate was 80 bpm. Physical examination revealed no stigmata of Marfan syndrome. The rest of his physical examination was normal.'''\n",
    "\n",
    "annotated_text = light_model.annotate(source_text)\n",
    "annotated_text['deidentified']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4.Clinical_DeIdentificiation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
